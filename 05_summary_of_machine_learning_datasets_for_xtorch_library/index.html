
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://kamisaberi.github.io/xtorch/05_summary_of_machine_learning_datasets_for_xtorch_library/">
      
      
        <link rel="prev" href="../04_comprehensive_machine_learning_datasets_for_xtorch_library/">
      
      
        <link rel="next" href="../api/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.12">
    
    
      
        <title>Summary of Machine Learning Datasets for xtorch Library - xTorch</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.2afb09e1.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#summary-of-machine-learning-datasets-for-xtorch-library" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="xTorch" class="md-header__button md-logo" aria-label="xTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            xTorch
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Summary of Machine Learning Datasets for xtorch Library
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/kamisaberi/xtorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="xTorch" class="md-nav__button md-logo" aria-label="xTorch" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    xTorch
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/kamisaberi/xtorch" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../00_datasets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    00 datasets
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../01_datasets_for_xtorch_library_not_in_pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Datasets for xtorch Library Not in PyTorch
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../02_datasets_for_xtorch_library_not_in_pytorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Additional Datasets for xtorch Library Not in PyTorch
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../03_machine_learning_datasets_for_%20xtorch_library/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Machine Learning Datasets Similar to IRIS for xtorch Library
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../04_comprehensive_machine_learning_datasets_for_xtorch_library/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comprehensive Machine Learning Datasets for xtorch Library
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Summary of Machine Learning Datasets for xtorch Library
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Summary of Machine Learning Datasets for xtorch Library
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evolution-of-the-conversation" class="md-nav__link">
    <span class="md-ellipsis">
      Evolution of the Conversation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-points" class="md-nav__link">
    <span class="md-ellipsis">
      Key Points
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comprehensive-dataset-table" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Dataset Table
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Considerations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-more-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      Finding More Datasets
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-citations" class="md-nav__link">
    <span class="md-ellipsis">
      Key Citations
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    API
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Contributing
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../domain_specific_image_transforms_table/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Domain specific image transforms table
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../features/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Features
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../license/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    License
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../list_of_albumentations_image_transforms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    List of albumentations image transforms
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../list_of_opencV_image_transforms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    list of opencV image transforms
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../quickstart/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quick Start
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_17" >
        
          
          <label class="md-nav__link" for="__nav_17" id="__nav_17_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Api
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_17_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_17">
            <span class="md-nav__icon md-icon"></span>
            Api
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Index
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/ref/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    REF
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_17_3" >
        
          
          <label class="md-nav__link" for="__nav_17_3" id="__nav_17_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Cpp
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_17_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_17_3">
            <span class="md-nav__icon md-icon"></span>
            Cpp
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/cpp/core_classes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    core_classes.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/cpp/native/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    native.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/cpp/tensor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    tensor.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_17_4" >
        
          
          <label class="md-nav__link" for="__nav_17_4" id="__nav_17_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Python
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_17_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_17_4">
            <span class="md-nav__icon md-icon"></span>
            Python
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/python/core/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    core.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/python/nn/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    nn.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/python/optim/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    optim.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../api/python/utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    utils.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_18" >
        
          
          <label class="md-nav__link" for="__nav_18" id="__nav_18_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Community
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_18_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_18">
            <span class="md-nav__icon md-icon"></span>
            Community
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../community/code_of_conduct/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    code_of_conduct.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../community/faq/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    faq.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_19" >
        
          
          <label class="md-nav__link" for="__nav_19" id="__nav_19_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Developer
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_19_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_19">
            <span class="md-nav__icon md-icon"></span>
            Developer
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer/benchmarks/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    benchmarks.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer/contributing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    contributing.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../developer/testing/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    testing.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_20" >
        
          
          <label class="md-nav__link" for="__nav_20" id="__nav_20_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Ecosystem
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_20_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_20">
            <span class="md-nav__icon md-icon"></span>
            Ecosystem
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ecosystem/integration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    integration.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ecosystem/nlp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    nlp.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ecosystem/vision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    vision.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21" >
        
          
          <label class="md-nav__link" for="__nav_21" id="__nav_21_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_21_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/0_examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    0 examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/comprehensive_example_titles_for_xtorch_library/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comprehensive Example Titles for xtorch Library
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/comprehensive_example_titles_for_xtorch_library_with_medical_and_biological_applications/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Comprehensive Example Titles for xtorch Library with Medical and Biological Applications
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_4" >
        
          
          <label class="md-nav__link" for="__nav_21_4" id="__nav_21_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Audio and speech
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_4">
            <span class="md-nav__icon md-icon"></span>
            Audio and speech
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/audio_and_speech/4_1_speech_recognition_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4 1 speech recognition examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/audio_and_speech/4_2_audio_classification_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    4 2 audio classification examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_5" >
        
          
          <label class="md-nav__link" for="__nav_21_5" id="__nav_21_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Computer vision
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_5">
            <span class="md-nav__icon md-icon"></span>
            Computer vision
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/computer_vision/2_1_image_classification_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 1 image classification examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/computer_vision/2_2_object_detection_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 2 object detection examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/computer_vision/2_3_segmentation_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 3 segmentation examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/computer_vision/2_4_image_generation_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    2 4 image generation examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_6" >
        
          
          <label class="md-nav__link" for="__nav_21_6" id="__nav_21_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Data handling and preprocessing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_6">
            <span class="md-nav__icon md-icon"></span>
            Data handling and preprocessing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/data_handling_and_preprocessing/10_1_datasets_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10 1 datasets examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/data_handling_and_preprocessing/10_2_data_loaders_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10 2 data loaders examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/data_handling_and_preprocessing/10_3_transforms_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    10 3 transforms examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_7" >
        
          
          <label class="md-nav__link" for="__nav_21_7" id="__nav_21_7_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Deployment and production
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_7">
            <span class="md-nav__icon md-icon"></span>
            Deployment and production
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/deployment_and_production/9_1_model_serialization_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9 1 model serialization examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/deployment_and_production/9_2_inference_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9 2 inference examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/deployment_and_production/9_3_web_services_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    9 3 web services examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_8" >
        
          
          <label class="md-nav__link" for="__nav_21_8" id="__nav_21_8_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Distributed and parallel training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_8">
            <span class="md-nav__icon md-icon"></span>
            Distributed and parallel training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/distributed_and_parallel_training/13_1_data_parallelism_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13 1 data parallelism examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/distributed_and_parallel_training/13_2_model_parallelism_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13 2 model parallelism examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/distributed_and_parallel_training/13_3_distributed_training_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    13 3 distributed training examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_9" >
        
          
          <label class="md-nav__link" for="__nav_21_9" id="__nav_21_9_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Generative models
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_9">
            <span class="md-nav__icon md-icon"></span>
            Generative models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/generative_models/8_1_autoencoders_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8 1 autoencoders examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/generative_models/8_2_gans_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8 2 gans examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/generative_models/8_3_diffusion_models_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    8 3 diffusion models examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_10" >
        
          
          <label class="md-nav__link" for="__nav_21_10" id="__nav_21_10_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_10_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_10">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/getting_started/1_getting_started_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    1 getting started examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_11" >
        
          
          <label class="md-nav__link" for="__nav_21_11" id="__nav_21_11_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Graph neural networks
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_11">
            <span class="md-nav__icon md-icon"></span>
            Graph neural networks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/graph_neural_networks/7_1_node_level_tasks_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7 1 node level tasks examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/graph_neural_networks/7_2_graph_level_tasks_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    7 2 graph level tasks examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_12" >
        
          
          <label class="md-nav__link" for="__nav_21_12" id="__nav_21_12_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Natural language processing
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_12_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_12">
            <span class="md-nav__icon md-icon"></span>
            Natural language processing
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/natural_language_processing/3_1_text_classification_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 1 text classification examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/natural_language_processing/3_2_sequence_to_sequence_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 2 sequence to sequence examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/natural_language_processing/3_3_language_modeling_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    3 3 language modeling examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_13" >
        
          
          <label class="md-nav__link" for="__nav_21_13" id="__nav_21_13_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Optimization and training techniques
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_13_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_13">
            <span class="md-nav__icon md-icon"></span>
            Optimization and training techniques
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/optimization_and_training_techniques/11_1_optimizers_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11 1 optimizers examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/optimization_and_training_techniques/11_2_learning_rate_schedulers_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11 2 learning rate schedulers examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/optimization_and_training_techniques/11_3_regularization_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    11 3 regularization examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_14" >
        
          
          <label class="md-nav__link" for="__nav_21_14" id="__nav_21_14_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Performance and benchmarking
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_14_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_14">
            <span class="md-nav__icon md-icon"></span>
            Performance and benchmarking
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/performance_and_benchmarking/12_1_speed_optimization_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12 1 speed optimization examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/performance_and_benchmarking/12_2_memory_management_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    12 2 memory management examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_15" >
        
          
          <label class="md-nav__link" for="__nav_21_15" id="__nav_21_15_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Reinforcement learning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_15_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_15">
            <span class="md-nav__icon md-icon"></span>
            Reinforcement learning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/reinforcement_learning/6_1_value_based_methods_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6 1 value based methods examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/reinforcement_learning/6_2_policy_based_methods_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    6 2 policy based methods examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_21_16" >
        
          
          <label class="md-nav__link" for="__nav_21_16" id="__nav_21_16_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Time series and sequential data
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_21_16_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_21_16">
            <span class="md-nav__icon md-icon"></span>
            Time series and sequential data
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/time_series_and_sequential_data/5_1_forecasting_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 1 forecasting examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../examples/time_series_and_sequential_data/5_2_anomaly_detection_examples_for_xtorch/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    5 2 anomaly detection examples for xtorch
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_22" >
        
          
          <label class="md-nav__link" for="__nav_22" id="__nav_22_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Getting started
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_22_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_22">
            <span class="md-nav__icon md-icon"></span>
            Getting started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/installation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    xTorch Installation Guide
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/migration_guide/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    migration_guide.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting_started/quickstart_tutorial/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    quickstart_tutorial.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_23" >
        
          
          <label class="md-nav__link" for="__nav_23" id="__nav_23_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Installation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_23_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_23">
            <span class="md-nav__icon md-icon"></span>
            Installation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../installation/System%20Dependency%20Installer%20Script%20Documentation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    System Dependency Installer Script Documentation
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_24" >
        
          
          <label class="md-nav__link" for="__nav_24" id="__nav_24_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Publications
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_24_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_24">
            <span class="md-nav__icon md-icon"></span>
            Publications
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../publications/extensive_list_of_deep_learning_papers_for_pytorch_on_papar_with_code_com_rewrite/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Extensive List of Deep Learning Papers for PyTorch Rewrite
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../publications/extensive_list_of_deep_learning_papers_for_pytorch_rewrite/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Extensive List of Deep Learning Papers for PyTorch Rewrite
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_25" >
        
          
          <label class="md-nav__link" for="__nav_25" id="__nav_25_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Roadmaps
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_25_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_25">
            <span class="md-nav__icon md-icon"></span>
            Roadmaps
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roadmaps/datasets/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transforms Roadmap
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roadmaps/models/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Datasets Roadmap
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../roadmaps/transforms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Transforms Roadmap
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_26" >
        
          
          <label class="md-nav__link" for="__nav_26" id="__nav_26_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tutorials
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_26_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_26">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/settings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Settings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_26_2" >
        
          
          <label class="md-nav__link" for="__nav_26_2" id="__nav_26_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Advanced
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_26_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_26_2">
            <span class="md-nav__icon md-icon"></span>
            Advanced
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/advanced/cpp_extensions/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    cpp_extensions.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/advanced/jit_compilation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    jit_compilation.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_26_3" >
        
          
          <label class="md-nav__link" for="__nav_26_3" id="__nav_26_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Basics
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_26_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_26_3">
            <span class="md-nav__icon md-icon"></span>
            Basics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/basics/custom_layers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    custom_layers.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/basics/hello_world/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hello World
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/basics/working_with_tensors/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    working_with_tensors.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_26_4" >
        
          
          <label class="md-nav__link" for="__nav_26_4" id="__nav_26_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Intermediate
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_26_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_26_4">
            <span class="md-nav__icon md-icon"></span>
            Intermediate
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/intermediate/gpu_acceleration/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    gpu_acceleration.md
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tutorials/intermediate/mixed_precision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    mixed_precision.md
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evolution-of-the-conversation" class="md-nav__link">
    <span class="md-ellipsis">
      Evolution of the Conversation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-points" class="md-nav__link">
    <span class="md-ellipsis">
      Key Points
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#comprehensive-dataset-table" class="md-nav__link">
    <span class="md-ellipsis">
      Comprehensive Dataset Table
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-considerations" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Considerations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#finding-more-datasets" class="md-nav__link">
    <span class="md-ellipsis">
      Finding More Datasets
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    <span class="md-ellipsis">
      Conclusion
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#key-citations" class="md-nav__link">
    <span class="md-ellipsis">
      Key Citations
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="summary-of-machine-learning-datasets-for-xtorch-library">Summary of Machine Learning Datasets for xtorch Library</h1>
<h2 id="overview">Overview</h2>
<p>Our conversation focused on identifying machine learning datasets that are not currently implemented in PyTorchs core libraries (<code>torchvision</code>, <code>torchaudio</code>, <code>torchtext</code>) for potential inclusion in a custom "xtorch" library. The discussion began with a request for datasets not in PyTorch, followed by clarifications to include datasets similar to IRIS (small, tabular, classification-focused) and ultimately expanded to encompass all machine learning datasets across various domains and tasks. The datasets were selected to cover a wide range of applications, including computer vision, NLP, audio processing, time series, graph data, reinforcement learning, recommendation systems, geospatial analysis, and more. The goal was to provide a comprehensive, diverse set of datasets to enhance "xtorch"s utility for educational, research, and industry purposes.</p>
<h2 id="evolution-of-the-conversation">Evolution of the Conversation</h2>
<ol>
<li><strong>Initial Request (Datasets Not in PyTorch)</strong>: You asked for datasets that could be included in "xtorch" but are not in PyTorchs core libraries. I provided a list of datasets across computer vision (e.g., ADE20K, Open Images), NLP (e.g., WMT14, Natural Questions), audio (e.g., AudioSet, UrbanSound8K), time series (e.g., M4 Competition, NAB), and graph data (e.g., Cora, OGB-MolHIV), emphasizing their absence in <code>torchvision</code>, <code>torchaudio</code>, and <code>torchtext</code>.</li>
<li><strong>Request for a Table</strong>: You requested a table format, which I provided, listing these datasets with details on domain, purpose, description, and why theyre suitable for "xtorch."</li>
<li><strong>Additional Datasets</strong>: You asked for more datasets, leading to a second table with datasets like Visual Genome (multimodal), Atari 2600 (reinforcement learning), FFHQ (generative modeling), and MovieLens (recommendation systems), covering emerging areas.</li>
<li><strong>Focus on IRIS-Like Datasets</strong>: You clarified a need for datasets like IRIS (small, tabular, classification-focused), resulting in a table of 15 datasets (e.g., Palmer Penguin, Breast Cancer Wisconsin, Pima Indians Diabetes), all tabular and used for classification.</li>
<li><strong>Expanded IRIS-Like Datasets</strong>: You requested a larger table, which I expanded to 25 datasets, including additional tabular datasets like Ionosphere, Glass Identification, and Thyroid Disease, maintaining the classification focus.</li>
<li><strong>All Machine Learning Datasets</strong>: You corrected that you wanted all machine learning datasets, not just IRIS-like ones. I provided a comprehensive table of 40 datasets, covering tabular (e.g., Iris, Boston Housing), image (e.g., MNIST, ImageNet), text (e.g., IMDB Reviews, SQuAD), audio (e.g., LIBRISPEECH, ESC-50), video (e.g., Kinetics), 3D (e.g., ModelNet40), graphs (e.g., Freebase), and simulations (e.g., MuJoCo), across tasks like classification, regression, NLP, and reinforcement learning.</li>
<li><strong>Final Request (Big Brief)</strong>: You asked for a "big brief" summarizing everything discussed, leading to this consolidated overview.</li>
</ol>
<h2 id="key-points">Key Points</h2>
<ul>
<li><strong>Dataset Diversity</strong>: The datasets span multiple domains (e.g., healthcare, computer vision, NLP, reinforcement learning) and tasks (e.g., classification, regression, object detection, speech recognition), ensuring "xtorch" can support a wide range of machine learning applications.</li>
<li><strong>Data Types</strong>: Includes tabular (e.g., Iris, Adult Census), image (e.g., COCO, ImageNet), text (e.g., WMT14, SNLI), audio (e.g., TIMIT, AudioSet), video (e.g., YouTube-8M), 3D point clouds (e.g., ScanNet), graphs (e.g., Wikidata5M), and simulation environments (e.g., Atari 2600).</li>
<li><strong>Scale</strong>: Ranges from small datasets (e.g., Iris: 150 samples) to massive ones (e.g., LAION-5B: 5.85 billion samples), catering to both beginners and advanced users.</li>
<li><strong>Absence in PyTorch</strong>: Most datasets are not in PyTorchs core libraries (v2.7.0 as of May 2025), though some (e.g., MNIST, LIBRISPEECH) may be partially supported in extensions. They were included if not standard in stable releases, ensuring novelty for "xtorch."</li>
<li><strong>Sources</strong>: Datasets are sourced from UCI Machine Learning Repository, Kaggle, Papers with Code, Hugging Face, and domain-specific repositories (e.g., ADNI, TCGA), with public access or minimal registration requirements.</li>
<li><strong>Implementation</strong>: Datasets can be implemented as <code>torch.utils.data.Dataset</code> subclasses in Python or custom C++ loaders in LibTorch, with preprocessing for tabular (e.g., encoding categorical features), image (e.g., normalization), and text (e.g., tokenization) data.</li>
</ul>
<h2 id="comprehensive-dataset-table">Comprehensive Dataset Table</h2>
<p>The table below consolidates all datasets discussed, organized by domain, with details on task, data type, description, sample size, features, classes (if applicable), source, and why theyre suitable for "xtorch." This table merges datasets from all previous responses, ensuring a complete summary.</p>
<table>
<thead>
<tr>
<th>Dataset Name</th>
<th>Domain</th>
<th>Task</th>
<th>Data Type</th>
<th>Description</th>
<th>Samples</th>
<th>Features</th>
<th>Classes</th>
<th>Source</th>
<th>Why for xtorch</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Iris Dataset</strong></td>
<td>Botany</td>
<td>Classification</td>
<td>Tabular</td>
<td>Measurements of iris flowers to classify species (setosa, versicolor, virginica).</td>
<td>150</td>
<td>4</td>
<td>3</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Iris">UCI</a></td>
<td>Beginner-friendly, standard classification benchmark, small and tabular.</td>
</tr>
<tr>
<td><strong>Palmer Penguin Dataset</strong></td>
<td>Zoology</td>
<td>Classification</td>
<td>Tabular</td>
<td>Penguin measurements to classify species (Adelie, Chinstrap, Gentoo).</td>
<td>344</td>
<td>7</td>
<td>3</td>
<td><a href="https://allisonhorst.github.io/palmerpenguins/">Palmer Penguins</a></td>
<td>Modern IRIS alternative, educational, multi-class classification.</td>
</tr>
<tr>
<td><strong>Breast Cancer Wisconsin</strong></td>
<td>Healthcare</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Features from breast mass images to classify tumors (malignant/benign).</td>
<td>569</td>
<td>30</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">UCI</a></td>
<td>Healthcare application, widely used for binary classification.</td>
</tr>
<tr>
<td><strong>Pima Indians Diabetes</strong></td>
<td>Healthcare</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Diagnostic measurements to predict diabetes in Pima Indian women.</td>
<td>768</td>
<td>8</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes">UCI</a></td>
<td>Classic healthcare dataset, supports binary classification.</td>
</tr>
<tr>
<td><strong>Wine Dataset</strong></td>
<td>Agriculture/Chemistry</td>
<td>Classification</td>
<td>Tabular</td>
<td>Chemical analysis of wines to classify cultivars.</td>
<td>178</td>
<td>13</td>
<td>3</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Wine">UCI</a></td>
<td>Small, balanced, multi-class classification benchmark.</td>
</tr>
<tr>
<td><strong>Sonar, Mines vs. Rocks</strong></td>
<td>Signal Processing</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Sonar signals to classify mines or rocks.</td>
<td>208</td>
<td>60</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+(Sonar,+Mines+vs.+Rocks)">UCI</a></td>
<td>High-dimensional, tests complex classification algorithms.</td>
</tr>
<tr>
<td><strong>Statlog (Heart)</strong></td>
<td>Healthcare</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Medical data to classify heart disease presence.</td>
<td>270</td>
<td>13</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Statlog+(Heart)">UCI</a></td>
<td>Healthcare-focused, small tabular dataset.</td>
</tr>
<tr>
<td><strong>Banknote Authentication</strong></td>
<td>Finance/Security</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Banknote image features to classify as authentic or forged.</td>
<td>1,372</td>
<td>4</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Banknote+Authentication">UCI</a></td>
<td>Simple, real-world fraud detection application.</td>
</tr>
<tr>
<td><strong>Wheat Seeds</strong></td>
<td>Agriculture</td>
<td>Classification</td>
<td>Tabular</td>
<td>Wheat kernel measurements to classify varieties.</td>
<td>210</td>
<td>7</td>
<td>3</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/seeds">UCI</a></td>
<td>Agricultural focus, small tabular dataset.</td>
</tr>
<tr>
<td><strong>Adult Census Income</strong></td>
<td>Socioeconomics</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Census data to predict income &gt;$50K.</td>
<td>48,842</td>
<td>14</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Adult">UCI</a></td>
<td>Large-scale, socio-economic classification task.</td>
</tr>
<tr>
<td><strong>Car Evaluation</strong></td>
<td>Automotive</td>
<td>Classification</td>
<td>Tabular</td>
<td>Car attributes to classify acceptability (unacc, acc, good, vgood).</td>
<td>1,728</td>
<td>6</td>
<td>4</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Car+Evaluation">UCI</a></td>
<td>Categorical features, multi-class classification.</td>
</tr>
<tr>
<td><strong>Mushroom Dataset</strong></td>
<td>Biology</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Mushroom features to classify as edible or poisonous.</td>
<td>8,124</td>
<td>22</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Mushroom">UCI</a></td>
<td>Safety-related, mix of categorical and numerical features.</td>
</tr>
<tr>
<td><strong>Zoo Dataset</strong></td>
<td>Zoology</td>
<td>Classification</td>
<td>Tabular</td>
<td>Animal attributes to classify types (e.g., mammal, bird).</td>
<td>101</td>
<td>17</td>
<td>7</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Zoo">UCI</a></td>
<td>Small, biology-focused, multi-class classification.</td>
</tr>
<tr>
<td><strong>Balance Scale</strong></td>
<td>Physics</td>
<td>Classification</td>
<td>Tabular</td>
<td>Weights on a balance scale to classify tipping (left, balanced, right).</td>
<td>625</td>
<td>4</td>
<td>3</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Balance+Scale">UCI</a></td>
<td>Simple, physics-related, multi-class classification.</td>
</tr>
<tr>
<td><strong>Titanic Dataset</strong></td>
<td>Historical/Socioeconomics</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Passenger data to predict Titanic survival.</td>
<td>~891</td>
<td>Several</td>
<td>2</td>
<td><a href="https://www.kaggle.com/c/titanic">Kaggle</a></td>
<td>Popular, real-world context, beginner-friendly.</td>
</tr>
<tr>
<td><strong>Ionosphere</strong></td>
<td>Physics/Engineering</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Radar data to classify ionospheric structures (good/bad).</td>
<td>351</td>
<td>34</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Ionosphere">UCI</a></td>
<td>High-dimensional, engineering-focused classification.</td>
</tr>
<tr>
<td><strong>Glass Identification</strong></td>
<td>Material Science</td>
<td>Classification</td>
<td>Tabular</td>
<td>Chemical properties to classify glass types.</td>
<td>214</td>
<td>9</td>
<td>6</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Glass+Identification">UCI</a></td>
<td>Small, material science, multi-class classification.</td>
</tr>
<tr>
<td><strong>Vertebral Column</strong></td>
<td>Healthcare</td>
<td>Classification</td>
<td>Tabular</td>
<td>Biomechanical features to classify spinal conditions.</td>
<td>310</td>
<td>6</td>
<td>3</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Vertebral+Column">UCI</a></td>
<td>Healthcare, small tabular dataset.</td>
</tr>
<tr>
<td><strong>Habermans Survival</strong></td>
<td>Healthcare</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Surgical data to predict breast cancer survival.</td>
<td>306</td>
<td>3</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Haberman%27s+Survival">UCI</a></td>
<td>Small, healthcare binary classification.</td>
</tr>
<tr>
<td><strong>Thyroid Disease</strong></td>
<td>Healthcare</td>
<td>Classification</td>
<td>Tabular</td>
<td>Medical measurements to classify thyroid conditions (normal, hyper, hypo).</td>
<td>7,200</td>
<td>21</td>
<td>3</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Thyroid+Disease">UCI</a></td>
<td>Larger healthcare dataset, multi-class classification.</td>
</tr>
<tr>
<td><strong>Abalone</strong></td>
<td>Marine Biology</td>
<td>Regression/Classification</td>
<td>Tabular</td>
<td>Measurements of abalones to predict age (rings).</td>
<td>4,177</td>
<td>8</td>
<td>29 (or grouped)</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Abalone">UCI</a></td>
<td>Versatile for regression or classification, biological focus.</td>
</tr>
<tr>
<td><strong>Ecoli</strong></td>
<td>Microbiology</td>
<td>Classification</td>
<td>Tabular</td>
<td>Protein features to classify Ecoli cellular locations.</td>
<td>336</td>
<td>7</td>
<td>8</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Ecoli">UCI</a></td>
<td>Small, biology-focused, multi-class classification.</td>
</tr>
<tr>
<td><strong>Yeast</strong></td>
<td>Microbiology</td>
<td>Classification</td>
<td>Tabular</td>
<td>Cellular features to classify yeast protein localization sites.</td>
<td>1,484</td>
<td>8</td>
<td>10</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Yeast">UCI</a></td>
<td>Medium-sized, complex biological classification.</td>
</tr>
<tr>
<td><strong>Credit Approval</strong></td>
<td>Finance</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Anonymized credit application data to approve/deny credit.</td>
<td>690</td>
<td>15</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Credit+Approval">UCI</a></td>
<td>Real-world finance, binary classification.</td>
</tr>
<tr>
<td><strong>German Credit</strong></td>
<td>Finance</td>
<td>Binary Classification</td>
<td>Tabular</td>
<td>Customer data to classify credit risk (good/bad).</td>
<td>1,000</td>
<td>20</td>
<td>2</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">UCI</a></td>
<td>Finance-focused, real-world classification.</td>
</tr>
<tr>
<td><strong>Boston Housing</strong></td>
<td>Real Estate</td>
<td>Regression</td>
<td>Tabular</td>
<td>Housing data to predict house prices in Boston.</td>
<td>506</td>
<td>13</td>
<td>N/A</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/Housing">UCI</a></td>
<td>Standard regression benchmark, small tabular dataset.</td>
</tr>
<tr>
<td><strong>ADE20K</strong></td>
<td>Computer Vision</td>
<td>Scene Parsing</td>
<td>Image</td>
<td>Images with pixel-level annotations for semantic/instance segmentation.</td>
<td>20,210</td>
<td>Varies</td>
<td>150</td>
<td><a href="http://groups.csail.mit.edu/vision/datasets/ADE20K/">ADE20K</a></td>
<td>Detailed scene analysis, complements Cityscapes.</td>
</tr>
<tr>
<td><strong>Open Images</strong></td>
<td>Computer Vision</td>
<td>Object Detection</td>
<td>Image</td>
<td>9M+ images with bounding boxes, segmentation masks, and labels.</td>
<td>9M+</td>
<td>Varies</td>
<td>600</td>
<td><a href="https://storage.googleapis.com/openimages/web/index.html">Open Images</a></td>
<td>Large-scale object detection, beyond COCO.</td>
</tr>
<tr>
<td><strong>LVIS</strong></td>
<td>Computer Vision</td>
<td>Instance Segmentation</td>
<td>Image</td>
<td>164,000 annotations across 1,200+ object categories.</td>
<td>164,000</td>
<td>Varies</td>
<td>1,200+</td>
<td><a href="https://www.lvisdataset.org/">LVIS</a></td>
<td>Long-tail recognition, enhances segmentation.</td>
</tr>
<tr>
<td><strong>DAVIS</strong></td>
<td>Computer Vision</td>
<td>Video Object Segmentation</td>
<td>Video</td>
<td>150 video sequences with pixel-level object tracking.</td>
<td>150</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://davischallenge.org/">DAVIS</a></td>
<td>Video analysis, complements Kinetics.</td>
</tr>
<tr>
<td><strong>ChestX-ray14</strong></td>
<td>Healthcare</td>
<td>Classification</td>
<td>Medical Imaging</td>
<td>112,120 X-ray images labeled for 14 thoracic diseases.</td>
<td>112,120</td>
<td>Varies</td>
<td>14</td>
<td><a href="https://nihcc.app.box.com/v/ChestXray-NIHCC">NIH</a></td>
<td>Medical imaging, healthcare application.</td>
</tr>
<tr>
<td><strong>ISIC Skin Cancer</strong></td>
<td>Healthcare</td>
<td>Classification/Segmentation</td>
<td>Medical Imaging</td>
<td>23,000+ dermoscopic images for skin cancer detection.</td>
<td>23,000+</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://www.isic-archive.com/">ISIC</a></td>
<td>Dermatology-focused medical imaging.</td>
</tr>
<tr>
<td><strong>BraTS</strong></td>
<td>Healthcare</td>
<td>Segmentation</td>
<td>Medical Imaging</td>
<td>MRI scans for brain tumor detection and segmentation.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://www.med.upenn.edu/cbica/brats2023/">BraTS</a></td>
<td>Advanced medical imaging, complements ChestX-ray14.</td>
</tr>
<tr>
<td><strong>Waymo Open Dataset</strong></td>
<td>Autonomous Driving</td>
<td>Perception</td>
<td>Image+Lidar</td>
<td>Lidar, camera, radar data for 3D object detection.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://waymo.com/open/">Waymo</a></td>
<td>Autonomous driving, beyond KITTI.</td>
</tr>
<tr>
<td><strong>nuScenes</strong></td>
<td>Autonomous Driving</td>
<td>Perception</td>
<td>Image+Lidar</td>
<td>3D annotations for object detection/tracking in driving scenarios.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://www.nuscenes.org/">nuScenes</a></td>
<td>Diverse driving data, complements Waymo.</td>
</tr>
<tr>
<td><strong>WMT14</strong></td>
<td>NLP</td>
<td>Machine Translation</td>
<td>Text</td>
<td>English-German parallel corpora for translation.</td>
<td>Millions</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="http://www.statmt.org/wmt14/">WMT</a></td>
<td>Standard translation benchmark.</td>
</tr>
<tr>
<td><strong>Natural Questions</strong></td>
<td>NLP</td>
<td>Question Answering</td>
<td>Text</td>
<td>307,373 questions for open-domain QA from Google.</td>
<td>307,373</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://ai.google.com/research/NaturalQuestions">Google</a></td>
<td>Open-domain QA, beyond SQuAD.</td>
</tr>
<tr>
<td><strong>TriviaQA</strong></td>
<td>NLP</td>
<td>Question Answering</td>
<td>Text</td>
<td>95,000 trivia questions for knowledge-based QA.</td>
<td>95,000</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://nlp.cs.washington.edu/triviaqa/">TriviaQA</a></td>
<td>Knowledge-intensive QA, complements SQuAD.</td>
</tr>
<tr>
<td><strong>HotpotQA</strong></td>
<td>NLP</td>
<td>Multi-hop QA</td>
<td>Text</td>
<td>Multi-hop QA requiring reasoning across documents.</td>
<td>Varies</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://hotpotqa.github.io/">HotpotQA</a></td>
<td>Complex QA, not in <code>torchtext</code>.</td>
</tr>
<tr>
<td><strong>CNN/DailyMail</strong></td>
<td>NLP</td>
<td>Text Summarization</td>
<td>Text</td>
<td>News articles with human-written summaries.</td>
<td>Varies</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://github.com/abisee/cnn-dailymail">GitHub</a></td>
<td>Abstractive summarization, key NLP task.</td>
</tr>
<tr>
<td><strong>XSum</strong></td>
<td>NLP</td>
<td>Text Summarization</td>
<td>Text</td>
<td>News articles with single-sentence summaries.</td>
<td>Varies</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://github.com/EdinburghNLP/XSum">GitHub</a></td>
<td>Concise summarization, complements CNN/DailyMail.</td>
</tr>
<tr>
<td><strong>PersonaChat</strong></td>
<td>NLP</td>
<td>Dialogue Generation</td>
<td>Text</td>
<td>Conversational dataset with persona information.</td>
<td>Varies</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://parl.ai/projects/personachat/">ParlAI</a></td>
<td>Dialogue systems, not in <code>torchtext</code>.</td>
</tr>
<tr>
<td><strong>DailyDialog</strong></td>
<td>NLP</td>
<td>Dialogue Generation</td>
<td>Text</td>
<td>Multi-turn dialogues for conversational modeling.</td>
<td>Varies</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="http://yanran.li/dailydialog.html">DailyDialog</a></td>
<td>Conversational AI, complements text tasks.</td>
</tr>
<tr>
<td><strong>AudioSet</strong></td>
<td>Audio Processing</td>
<td>Audio Event Detection</td>
<td>Audio</td>
<td>2M 10-second clips with 527 event classes from YouTube.</td>
<td>2M</td>
<td>N/A</td>
<td>527</td>
<td><a href="https://research.google.com/audioset/">Google</a></td>
<td>Large-scale audio event detection, beyond SPEECHCOMMANDS.</td>
</tr>
<tr>
<td><strong>UrbanSound8K</strong></td>
<td>Audio Processing</td>
<td>Environmental Sound Classification</td>
<td>Audio</td>
<td>8,732 urban sound excerpts across 10 classes (e.g., car horn).</td>
<td>8,732</td>
<td>N/A</td>
<td>10</td>
<td><a href="https://urbansounddataset.weebly.com/urbansound8k.html">UrbanSound</a></td>
<td>Environmental sound classification, not in <code>torchaudio</code>.</td>
</tr>
<tr>
<td><strong>FSD50K</strong></td>
<td>Audio Processing</td>
<td>Sound Event Detection</td>
<td>Audio</td>
<td>51,197 audio clips across 200 classes for sound event detection.</td>
<td>51,197</td>
<td>N/A</td>
<td>200</td>
<td><a href="https://zenodo.org/record/4060432">Zenodo</a></td>
<td>Diverse sound event detection, complements AudioSet.</td>
</tr>
<tr>
<td><strong>MagnaTagATune</strong></td>
<td>Audio Processing</td>
<td>Music Tagging</td>
<td>Audio</td>
<td>25,863 music tracks with 188 tags for music information retrieval.</td>
<td>25,863</td>
<td>N/A</td>
<td>188</td>
<td><a href="http://mirg.city.ac.uk/codeapps/the-magnatagatune-dataset">MIRG</a></td>
<td>Music analysis, not in <code>torchaudio</code>.</td>
</tr>
<tr>
<td><strong>Million Song Dataset</strong></td>
<td>Audio Processing</td>
<td>Music Information Retrieval</td>
<td>Audio+Metadata</td>
<td>1M songs with metadata and audio features for recommendation.</td>
<td>1M</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://labrosa.ee.columbia.edu/millionsong/">Columbia</a></td>
<td>Large-scale music analysis, complements GTZAN.</td>
</tr>
<tr>
<td><strong>M4 Competition</strong></td>
<td>Time Series</td>
<td>Time Series Forecasting</td>
<td>Time Series</td>
<td>100,000 time series for forecasting across domains (e.g., finance).</td>
<td>100,000</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://mofc.unic.ac.cy/m4/">M4</a></td>
<td>Standard forecasting benchmark, not in PyTorch.</td>
</tr>
<tr>
<td><strong>NAB</strong></td>
<td>Time Series</td>
<td>Anomaly Detection</td>
<td>Time Series</td>
<td>58 time series for streaming anomaly detection.</td>
<td>58</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://github.com/numenta/NAB">GitHub</a></td>
<td>Real-time anomaly detection, not in PyTorch.</td>
</tr>
<tr>
<td><strong>UCR Time Series Archive</strong></td>
<td>Time Series</td>
<td>Time Series Classification</td>
<td>Time Series</td>
<td>128 datasets for time series classification and pattern recognition.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://www.cs.ucr.edu/~eamonn/time_series_data/">UCR</a></td>
<td>Classification benchmark, complements forecasting.</td>
</tr>
<tr>
<td><strong>Electricity Load Diagrams</strong></td>
<td>Time Series</td>
<td>Time Series Forecasting</td>
<td>Time Series</td>
<td>Electricity consumption time series for energy forecasting.</td>
<td>Varies</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014">UCI</a></td>
<td>Domain-specific forecasting, not in PyTorch.</td>
</tr>
<tr>
<td><strong>Cora</strong></td>
<td>Graph Data</td>
<td>Node Classification</td>
<td>Graph</td>
<td>Citation network with 2,708 nodes for semi-supervised classification.</td>
<td>2,708</td>
<td>Varies</td>
<td>7</td>
<td><a href="https://linqs.soe.ucsc.edu/data">LINQS</a></td>
<td>Standard graph benchmark, not in core PyTorch.</td>
</tr>
<tr>
<td><strong>OGB-MolHIV</strong></td>
<td>Graph Data</td>
<td>Molecular Property Prediction</td>
<td>Graph</td>
<td>Graph dataset for predicting HIV inhibition.</td>
<td>Varies</td>
<td>Varies</td>
<td>2</td>
<td><a href="https://ogb.stanford.edu/docs/dataset_overview/">OGB</a></td>
<td>Molecular graph tasks, not in core PyTorch.</td>
</tr>
<tr>
<td><strong>Visual Genome</strong></td>
<td>Multimodal</td>
<td>Visual Relationship Detection</td>
<td>Image+Text</td>
<td>108,077 images with objects, attributes, and relationships.</td>
<td>108,077</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://visualgenome.org/">Visual Genome</a></td>
<td>Multimodal vision-language tasks, not in PyTorch.</td>
</tr>
<tr>
<td><strong>LAION-5B</strong></td>
<td>Multimodal</td>
<td>Image-Text Pretraining</td>
<td>Image+Text</td>
<td>5.85B image-text pairs for multimodal pretraining (e.g., CLIP).</td>
<td>5.85B</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://laion.ai/laion-5b/">LAION</a></td>
<td>Massive scale, supports generative multimodal models.</td>
</tr>
<tr>
<td><strong>Atari 2600 (ALE)</strong></td>
<td>Reinforcement Learning</td>
<td>Reinforcement Learning</td>
<td>Game Environment</td>
<td>60 Atari 2600 games for training RL agents (e.g., Pong).</td>
<td>N/A</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://github.com/mgbellemare/Arcade-Learning-Environment">ALE</a></td>
<td>Standard RL benchmark, not in PyTorch.</td>
</tr>
<tr>
<td><strong>MuJoCo (Gym)</strong></td>
<td>Reinforcement Learning</td>
<td>Continuous Control</td>
<td>Simulation</td>
<td>Physics-based environments for robotic control (e.g., Walker2d).</td>
<td>N/A</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://mujoco.org/">MuJoCo</a></td>
<td>RL for robotics, complements Atari.</td>
</tr>
<tr>
<td><strong>FFHQ</strong></td>
<td>Generative Modeling</td>
<td>Image Generation</td>
<td>Image</td>
<td>70,000 high-resolution face images for generative modeling (e.g., GANs).</td>
<td>70,000</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://github.com/NVlabs/ffhq-dataset">GitHub</a></td>
<td>Advanced generative tasks, beyond CelebA.</td>
</tr>
<tr>
<td><strong>ShapeNet</strong></td>
<td>Generative Modeling</td>
<td>3D Shape Generation</td>
<td>3D Model</td>
<td>51,300 3D models across 55 categories for 3D reconstruction.</td>
<td>51,300</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://shapenet.org/">ShapeNet</a></td>
<td>3D generative modeling, emerging field.</td>
</tr>
<tr>
<td><strong>TIMIT</strong></td>
<td>Speech Processing</td>
<td>Speech Recognition</td>
<td>Audio</td>
<td>6,300 sentences by 630 speakers for phonetic analysis.</td>
<td>6,300</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://catalog.ldc.upenn.edu/LDC93S1">LDC</a></td>
<td>Fine-grained speech tasks, complements LIBRISPEECH.</td>
</tr>
<tr>
<td><strong>ESC-50</strong></td>
<td>Audio Processing</td>
<td>Environmental Sound Classification</td>
<td>Audio</td>
<td>2,000 5-second clips across 50 environmental sound classes.</td>
<td>2,000</td>
<td>N/A</td>
<td>50</td>
<td><a href="https://github.com/karolpiczak/ESC-50">GitHub</a></td>
<td>Compact environmental sound classification.</td>
</tr>
<tr>
<td><strong>MovieLens</strong></td>
<td>Recommendation Systems</td>
<td>Recommendation</td>
<td>Tabular</td>
<td>27M ratings for 58,000 movies by 280,000 users.</td>
<td>27M</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://grouplens.org/datasets/movielens/">GroupLens</a></td>
<td>Standard for recommendation systems, real-world application.</td>
</tr>
<tr>
<td><strong>Amazon Product Reviews</strong></td>
<td>Recommendation/NLP</td>
<td>Recommendation/Sentiment</td>
<td>Text+Tabular</td>
<td>Billions of product reviews for recommendation and sentiment analysis.</td>
<td>Billions</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://nijianmo.github.io/amazon/index.html">Amazon</a></td>
<td>Large-scale recommendation and NLP tasks.</td>
</tr>
<tr>
<td><strong>ADNI</strong></td>
<td>Healthcare</td>
<td>Classification</td>
<td>Medical Imaging</td>
<td>MRI, PET, clinical data for Alzheimers diagnosis/progression.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="http://adni.loni.usc.edu/">ADNI</a></td>
<td>Biomedical imaging, healthcare ML application.</td>
</tr>
<tr>
<td><strong>TCGA</strong></td>
<td>Healthcare</td>
<td>Classification</td>
<td>Genomics+Imaging</td>
<td>Genomic and imaging data for cancer subtype classification.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://www.cancer.gov/tcga">TCGA</a></td>
<td>Genomics integration, cutting-edge biomedical task.</td>
</tr>
<tr>
<td><strong>SpaceNet</strong></td>
<td>Geospatial</td>
<td>Object Detection</td>
<td>Satellite Imagery</td>
<td>High-resolution satellite imagery with building/road annotations.</td>
<td>Varies</td>
<td>Varies</td>
<td>Varies</td>
<td><a href="https://spacenet.ai/">SpaceNet</a></td>
<td>Geospatial analysis, satellite image processing.</td>
</tr>
<tr>
<td><strong>xView</strong></td>
<td>Geospatial</td>
<td>Object Detection</td>
<td>Satellite Imagery</td>
<td>Satellite imagery with 60 object classes for disaster response.</td>
<td>Varies</td>
<td>Varies</td>
<td>60</td>
<td><a href="https://xviewdataset.org/">xView</a></td>
<td>Complex geospatial tasks, humanitarian applications.</td>
</tr>
<tr>
<td><strong>MVTec AD</strong></td>
<td>Industrial</td>
<td>Anomaly Detection</td>
<td>Image</td>
<td>5,354 images of industrial objects for defect detection.</td>
<td>5,354</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://www.mvtec.com/company/research/datasets/mvtec-ad/">MVTec</a></td>
<td>Industrial anomaly detection, complements time series.</td>
</tr>
<tr>
<td><strong>Freebase</strong></td>
<td>Knowledge Graphs</td>
<td>Knowledge Graph Reasoning</td>
<td>Graph</td>
<td>Large-scale knowledge base with entities and relations.</td>
<td>Millions</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://developers.google.com/freebase">Freebase</a></td>
<td>Knowledge graph tasks, not in PyTorch.</td>
</tr>
<tr>
<td><strong>Wikidata5M</strong></td>
<td>Knowledge Graphs</td>
<td>Knowledge Graph Reasoning</td>
<td>Graph</td>
<td>5M entities and relations from Wikidata for graph-based tasks.</td>
<td>5M</td>
<td>Varies</td>
<td>N/A</td>
<td><a href="https://deepgraphlearning.github.io/project/wikidata5m">Wikidata5M</a></td>
<td>Scalable knowledge graph tasks, complements Freebase.</td>
</tr>
<tr>
<td><strong>GSM8K</strong></td>
<td>Education</td>
<td>Math Word Problems</td>
<td>Text</td>
<td>8.5k grade school math word problems requiring arithmetic reasoning.</td>
<td>8,500</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://paperswithcode.com/dataset/gsm8k">Papers with Code</a></td>
<td>Educational NLP, supports reasoning tasks.</td>
</tr>
<tr>
<td><strong>ModelNet40</strong></td>
<td>Computer Vision</td>
<td>3D Point Cloud Analysis</td>
<td>3D Point Cloud</td>
<td>12,311 CAD-generated meshes in 40 categories for 3D classification.</td>
<td>12,311</td>
<td>Varies</td>
<td>40</td>
<td><a href="https://modelnet.cs.princeton.edu/">ModelNet</a></td>
<td>3D computer vision, emerging field.</td>
</tr>
<tr>
<td><strong>ScanNet</strong></td>
<td>Computer Vision</td>
<td>Semantic Segmentation</td>
<td>RGB-D</td>
<td>1,513 annotated indoor scans with 20 classes of 3D voxelized objects.</td>
<td>1,513</td>
<td>Varies</td>
<td>20</td>
<td><a href="http://www.scan-net.org/">ScanNet</a></td>
<td>Indoor 3D segmentation, advanced vision tasks.</td>
</tr>
<tr>
<td><strong>Kinetics</strong></td>
<td>Computer Vision</td>
<td>Action Recognition</td>
<td>Video</td>
<td>Large-scale video dataset for human action recognition.</td>
<td>650,000</td>
<td>Varies</td>
<td>700</td>
<td><a href="https://deepmind.com/research/open-source/kinetics">Kinetics</a></td>
<td>Video-based action recognition, temporal modeling.</td>
</tr>
<tr>
<td><strong>YouTube-8M</strong></td>
<td>Computer Vision/NLP</td>
<td>Video Classification</td>
<td>Video+Text</td>
<td>6.1M YouTube video IDs with 3,862 visual entity annotations.</td>
<td>6.1M</td>
<td>Varies</td>
<td>3,862</td>
<td><a href="https://research.google.com/youtube8m/">YouTube-8M</a></td>
<td>Large-scale video, multimodal tasks.</td>
</tr>
</tbody>
</table>
<h2 id="implementation-considerations">Implementation Considerations</h2>
<ul>
<li><strong>Python</strong>: Datasets can be implemented as <code>torch.utils.data.Dataset</code> subclasses, handling tabular (e.g., CSV loading with <code>pandas</code>), image (e.g., <code>PIL</code> or <code>torchvision.io</code>), text (e.g., tokenization with <code>torchtext</code>), audio (e.g., spectrograms with <code>torchaudio</code>), and other data types. Preprocessing includes encoding categorical features, normalizing images, and tokenizing text.</li>
<li><strong>C++ (LibTorch)</strong>: Requires custom loaders to convert data to <code>torch::Tensor</code>, more complex due to limited LibTorch dataset support (e.g., only MNIST, CIFAR in <code>libtorchvision</code>). Feasible for small datasets but challenging for large ones like LAION-5B.</li>
<li><strong>Challenges</strong>: Handling missing values (e.g., Adult Census), encoding categorical data (e.g., Mushroom), normalizing images (e.g., ImageNet), and processing large-scale data (e.g., LAION-5B) require robust preprocessing pipelines.</li>
<li><strong>Licensing</strong>: Most datasets are open for non-commercial use (e.g., UCI, Kaggle), but some (e.g., ADNI, TCGA) require registration. Users should verify terms at provided URLs.</li>
</ul>
<h2 id="finding-more-datasets">Finding More Datasets</h2>
<p>Given the vast number of machine learning datasets (e.g., 677+ in UCI, thousands in Kaggle), the table covers a representative subset. Additional datasets can be found via:
- <strong>UCI Machine Learning Repository</strong>: 677+ datasets for classification, regression, clustering.
- <strong>Kaggle</strong>: Thousands of datasets, from niche to large-scale, with community notebooks.
- <strong>Papers with Code</strong>: Curated datasets for research tasks (vision, NLP, RL).
- <strong>Hugging Face</strong>: NLP and multimodal datasets.
- <strong>Google Dataset Search</strong>: 25M+ datasets, including government and academic data.
- <strong>OpenML</strong>: 21,000+ datasets for ML research.
- <strong>Data.gov</strong>: US government datasets (demographics, healthcare).
- <strong>AWS Open Data Registry</strong>: Cloud-hosted datasets.
- <strong>GitHub</strong>: Community lists like Awesome Public Datasets.</p>
<h2 id="conclusion">Conclusion</h2>
<p>The conversation covered a diverse set of machine learning datasets for "xtorch," starting with datasets absent from PyTorch (e.g., ADE20K, WMT14), expanding to IRIS-like tabular datasets (e.g., Palmer Penguin, Breast Cancer Wisconsin), and culminating in a comprehensive list of 40 datasets across all major ML domains and tasks. These datasets, ranging from small (Iris: 150 samples) to massive (LAION-5B: 5.85B samples), support tasks like classification, regression, object detection, NLP, speech recognition, reinforcement learning, and more. They are not in PyTorchs core libraries, making them ideal for enhancing "xtorch"s utility for educational, research, and industry applications. The table provides a consolidated view, with sources and justifications, and additional repositories are listed for exploring more datasets. If you need specific implementation code, further dataset details, or assistance with accessing repositories, please let me know!</p>
<h2 id="key-citations">Key Citations</h2>
<ul>
<li><a href="https://archive.ics.uci.edu/ml/datasets.php">UCI Machine Learning Repository</a></li>
<li><a href="https://www.kaggle.com/datasets">Kaggle</a></li>
<li><a href="https://paperswithcode.com/datasets">Papers with Code</a></li>
<li><a href="https://huggingface.co/datasets">Hugging Face</a></li>
<li><a href="https://datasetsearch.research.google.com/">Google Dataset Search</a></li>
<li><a href="https://365datascience.com/trending/public-datasets-machine-learning/">365 Data Science</a></li>
<li><a href="https://rubikscode.net/2021/07/19/top-23-best-public-datasets-for-practicing-machine-learning/">Rubiks Code</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">Wikipedia</a></li>
<li><a href="https://www.projectpro.io/article/100-machine-learning-datasets-curated-for-you/407">ProjectPro</a></li>
<li><a href="https://www.v7labs.com/blog/best-free-datasets-for-machine-learning">V7 Labs</a></li>
<li><a href="https://www.mygreatlearning.com/blog/dataset-in-machine-learning/">Great Learning</a></li>
<li><a href="https://research.aimultiple.com/datasets-for-ml/">AIMultiple</a></li>
<li><a href="https://www.openml.org/">OpenML</a></li>
<li><a href="https://www.data.gov/">Data.gov</a></li>
<li><a href="https://registry.opendata.aws/">AWS Open Data</a></li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.f8cc74c7.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.c8b220af.min.js"></script>
      
    
  </body>
</html>